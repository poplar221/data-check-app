# app.py

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import io

# ------------------------------------------------------------------------------------
# ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢æ•°
# ------------------------------------------------------------------------------------

def find_header_and_read_excel(file_path, sheet_name, keywords):
    """
    Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€æŒ‡å®šã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹è¡Œã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã—ã¦ç‰¹å®šã—ã€
    ãã®è¡Œã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§DataFrameã¨ã—ã¦è¿”ã—ã¾ã™ã€‚
    """
    if file_path is None:
        return None
    try:
        # ExcelFileã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦é–‹ãã“ã¨ã§ã€ã‚·ãƒ¼ãƒˆã®å­˜åœ¨ã‚’ç¢ºèªã—ã‚„ã™ãã™ã‚‹
        xls = pd.ExcelFile(file_path)
        if sheet_name not in xls.sheet_names:
            st.error(f"âš ï¸ '{file_path.name}' ã« '{sheet_name}' ã¨ã„ã†åå‰ã®ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return None
            
        df_temp = pd.read_excel(file_path, sheet_name=sheet_name, header=None)
        header_row_index = -1
        for i, row in df_temp.iterrows():
            row_str = ''.join(map(str, row.dropna().values))
            if all(keyword in row_str for keyword in keywords):
                header_row_index = i
                break
        
        if header_row_index != -1:
            st.info(f"ğŸ“„ '{file_path.name}' ã® '{sheet_name}' ã‚·ãƒ¼ãƒˆã‹ã‚‰ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ {header_row_index + 1} è¡Œç›®ã§ç™ºè¦‹ã—ã¾ã—ãŸã€‚")
            df = pd.read_excel(file_path, sheet_name=sheet_name, header=header_row_index)
            return df
        else:
            st.error(f"âš ï¸ '{file_path.name}' ã® '{sheet_name}' ã‚·ãƒ¼ãƒˆã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€ãƒ˜ãƒƒãƒ€ãƒ¼è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return None
    except Exception as e:
        st.error(f"âŒã‚¨ãƒ©ãƒ¼: '{file_path.name}' ã® '{sheet_name}' ã‚·ãƒ¼ãƒˆèª­ã¿è¾¼ã¿ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

def data_check_and_matching(df_zenki, df_touki, df_taishoku, col_employee_id, col_nyusha, col_seinengappi, col_salary1, col_salary2, error_check_config):
    """
    ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯ã¨ãƒãƒƒãƒãƒ³ã‚°å‡¦ç†ã‚’è¡Œã„ã€çµæœã‚’Excelãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ¡ãƒ¢ãƒªä¸Šã«ä¿å­˜ã—ã€
    ã‚µãƒãƒªãƒ¼æƒ…å ±ã‚‚ä¸€ç·’ã«è¿”ã—ã¾ã™ã€‚
    """
    summary = {}
    
    st.write("---")
    st.subheader("å‡¦ç†çŠ¶æ³")
    
    with st.spinner("STEP 1: å‰å‡¦ç†ã¨ã‚­ãƒ¼ä½œæˆã‚’å®Ÿè¡Œä¸­..."):
        dfz = df_zenki.copy()
        dft = df_touki.copy()
        dftai = df_taishoku.copy()
        
        all_dfs = [dfz, dft, dftai]
        
        # çµ¦ä¸åˆ—ã‚’æ•°å€¤ã«å¤‰æ›
        for df in [dfz, dft]:
            if col_salary1 in df.columns:
                df[col_salary1] = pd.to_numeric(df[col_salary1], errors='coerce')
            if col_salary2 in df.columns:
                df[col_salary2] = pd.to_numeric(df[col_salary2], errors='coerce')

        # æ—¥ä»˜åˆ—ã‚’æ—¥ä»˜å‹ã«å¤‰æ›
        for df in all_dfs:
            if col_nyusha in df.columns and col_seinengappi in df.columns:
                df[col_nyusha] = pd.to_datetime(df[col_nyusha].astype(str), errors='coerce')
                df[col_seinengappi] = pd.to_datetime(df[col_seinengappi].astype(str), errors='coerce')

        # ã‚­ãƒ¼ã®ä½œæˆ
        if col_employee_id in dfz.columns and col_employee_id in dft.columns and col_employee_id in dftai.columns:
            st.info(f"ğŸ”‘ ã€Œ{col_employee_id}ã€ã‚’ã‚­ãƒ¼ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚")
            for df in all_dfs:
                df['key'] = df[col_employee_id].astype(str)
        else:
            st.info(f"ğŸ”‘ ã€Œå…¥ç¤¾å¹´æœˆæ—¥ã€ã¨ã€Œç”Ÿå¹´æœˆæ—¥ã€ã®é€£çµæ–‡å­—åˆ—ã‚’ã‚­ãƒ¼ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚")
            for df in all_dfs:
                if col_nyusha in df.columns and col_seinengappi in df.columns:
                    df['key'] = df[col_nyusha].dt.strftime('%Y%m%d') + '_' + df[col_seinengappi].dt.strftime('%Y%m%d')
        st.success("âœ… ã‚­ãƒ¼ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    with st.spinner("STEP 2: åŸºæœ¬ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œä¸­..."):
        zenki_duplicates = dfz[dfz.duplicated(subset=['key'], keep=False)]
        touki_duplicates = dft[dft.duplicated(subset=['key'], keep=False)]
        summary['zenki_duplicates'] = len(zenki_duplicates)
        summary['touki_duplicates'] = len(touki_duplicates)
        
        zenki_age_errors = pd.DataFrame()
        touki_age_errors = pd.DataFrame()
        if col_nyusha in dfz.columns and col_seinengappi in dfz.columns:
            # NaTã§ãªã„è¡Œã®ã¿è¨ˆç®—
            valid_dates_z = dfz.dropna(subset=[col_nyusha, col_seinengappi])
            days_diff_z = (valid_dates_z[col_nyusha] - valid_dates_z[col_seinengappi]).dt.days
            dfz.loc[valid_dates_z.index, 'age_at_hire'] = (days_diff_z / 365.25).astype(int)
            zenki_age_errors = dfz[(dfz['age_at_hire'] < 15) | (dfz['age_at_hire'] >= 90)]

        if col_nyusha in dft.columns and col_seinengappi in dft.columns:
            valid_dates_t = dft.dropna(subset=[col_nyusha, col_seinengappi])
            days_diff_t = (valid_dates_t[col_nyusha] - valid_dates_t[col_seinengappi]).dt.days
            dft.loc[valid_dates_t.index, 'age_at_hire'] = (days_diff_t / 365.25).astype(int)
            touki_age_errors = dft[(dft['age_at_hire'] < 15) | (dft['age_at_hire'] >= 90)]
        summary['zenki_age_errors'] = len(zenki_age_errors)
        summary['touki_age_errors'] = len(touki_age_errors)
        st.success("âœ… åŸºæœ¬ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    
    with st.spinner("STEP 3: åœ¨ç±è€…ãƒ»é€€è·è€…ãƒãƒƒãƒãƒ³ã‚°ã‚’å®Ÿè¡Œä¸­..."):
        # åœ¨ç±è€…ç…§åˆ
        merged_df = pd.merge(dfz, dft, on='key', how='outer', indicator=True, suffixes=('_zenki', '_touki'))
        
        only_zenki_full = merged_df[merged_df['_merge'] == 'left_only']
        only_touki_full = merged_df[merged_df['_merge'] == 'right_only']
        both_full = merged_df[merged_df['_merge'] == 'both']

        summary['only_zenki'] = len(only_zenki_full) # é€€è·è€…å€™è£œ
        summary['only_touki'] = len(only_touki_full) # å…¥ç¤¾è€…
        summary['both'] = len(both_full) # åœ¨ç±è€…

        # é€€è·è€…ç…§åˆ
        retiree_merged = pd.merge(only_zenki_full[['key']], dftai[['key']], on='key', how='outer', indicator='retiree_check')
        retiree_missing_keys = retiree_merged[retiree_merged['retiree_check'] == 'left_only']
        retiree_not_candidate_keys = retiree_merged[retiree_merged['retiree_check'] == 'right_only']
        retiree_correct_keys = retiree_merged[retiree_merged['retiree_check'] == 'both']

        retiree_missing_full = pd.merge(retiree_missing_keys, dfz, on='key', how='left')
        retiree_not_candidate_full = pd.merge(retiree_not_candidate_keys, dftai, on='key', how='left')
        retiree_correct_full = pd.merge(retiree_correct_keys, dftai, on='key', how='left')
        summary['retiree_missing'] = len(retiree_missing_full)
        summary['retiree_not_candidate'] = len(retiree_not_candidate_full)
        summary['retiree_correct'] = len(retiree_correct_full)
        st.success("âœ… ãƒãƒƒãƒãƒ³ã‚°ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    with st.spinner("STEP 4: è¿½åŠ ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œä¸­..."):
        salary_decrease = pd.DataFrame()
        salary_increase_rate = pd.DataFrame()
        cumulative_salary_check = pd.DataFrame()
        cumulative_salary_check2 = pd.DataFrame()

        sal1_zenki, sal1_touki = f"{col_salary1}_zenki", f"{col_salary1}_touki"
        sal2_zenki, sal2_touki = f"{col_salary2}_zenki", f"{col_salary2}_touki"

        if error_check_config['salary_decrease_check'] and sal1_zenki in both_full.columns and sal1_touki in both_full.columns:
            temp_df = both_full.dropna(subset=[sal1_touki, sal1_zenki])
            salary_decrease = temp_df[temp_df[sal1_touki] < temp_df[sal1_zenki]]
        summary['salary_decrease'] = len(salary_decrease)

        if error_check_config['salary_increase_rate_check'] and sal1_zenki in both_full.columns and sal1_touki in both_full.columns:
            x = error_check_config['x_rate']
            temp_df = both_full.dropna(subset=[sal1_touki, sal1_zenki])
            salary_increase_rate = temp_df[temp_df[sal1_touki] >= temp_df[sal1_zenki] * (1 + x / 100)]
        summary['salary_increase_rate'] = len(salary_increase_rate)

        if error_check_config['cumulative_salary_check'] and sal1_zenki in both_full.columns and sal2_zenki in both_full.columns and sal2_touki in both_full.columns:
            y = error_check_config['y_months']
            temp_df = both_full.dropna(subset=[sal2_touki, sal2_zenki, sal1_zenki])
            cumulative_salary_check = temp_df[temp_df[sal2_touki] < temp_df[sal2_zenki] + temp_df[sal1_zenki] * y]
        summary['cumulative_salary_check'] = len(cumulative_salary_check)

        if error_check_config['cumulative_salary_check2'] and sal1_zenki in both_full.columns and sal2_zenki in both_full.columns and sal2_touki in both_full.columns:
            y = error_check_config['y_months']
            z = error_check_config['z_rate']
            temp_df = both_full.dropna(subset=[sal2_touki, sal2_zenki, sal1_zenki])
            cumulative_salary_check2 = temp_df[temp_df[sal2_touki] > (temp_df[sal2_zenki] + temp_df[sal1_zenki] * y) * (1 + z / 100)]
        summary['cumulative_salary_check2'] = len(cumulative_salary_check2)
        st.success("âœ… è¿½åŠ ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    with st.spinner("STEP 5: çµæœã‚’Excelãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ä¸­..."):
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            zenki_duplicates.to_excel(writer, sheet_name='å‰æœŸæœ«_ã‚­ãƒ¼é‡è¤‡', index=False)
            touki_duplicates.to_excel(writer, sheet_name='å½“æœŸæœ«_ã‚­ãƒ¼é‡è¤‡', index=False)
            zenki_age_errors.to_excel(writer, sheet_name='å‰æœŸæœ«_æ—¥ä»˜ã‚¨ãƒ©ãƒ¼', index=False)
            touki_age_errors.to_excel(writer, sheet_name='å½“æœŸæœ«_æ—¥ä»˜ã‚¨ãƒ©ãƒ¼', index=False)
            only_zenki_full.to_excel(writer, sheet_name='åœ¨ç±ç…§åˆ_å‰æœŸã®ã¿(é€€è·è€…å€™è£œ)', index=False)
            only_touki_full.to_excel(writer, sheet_name='åœ¨ç±ç…§åˆ_å½“æœŸã®ã¿(å…¥ç¤¾è€…)', index=False)
            both_full.to_excel(writer, sheet_name='åœ¨ç±ç…§åˆ_ä¸¡æ–¹(åœ¨ç±è€…)', index=False)
            retiree_missing_full.to_excel(writer, sheet_name='é€€è·è€…ç…§åˆ_ãƒ‡ãƒ¼ã‚¿ä¸åœ¨', index=False)
            retiree_not_candidate_full.to_excel(writer, sheet_name='é€€è·è€…ç…§åˆ_å€™è£œã§ãªã„', index=False)
            retiree_correct_full.to_excel(writer, sheet_name='é€€è·è€…ç…§åˆ_ä¸€è‡´', index=False)
            salary_decrease.to_excel(writer, sheet_name='çµ¦ä¸æ¸›é¡ãƒã‚§ãƒƒã‚¯', index=False)
            salary_increase_rate.to_excel(writer, sheet_name='çµ¦ä¸å¢—åŠ ç‡ãƒã‚§ãƒƒã‚¯', index=False)
            cumulative_salary_check.to_excel(writer, sheet_name='ç´¯è¨ˆçµ¦ä¸ãƒã‚§ãƒƒã‚¯', index=False)
            cumulative_salary_check2.to_excel(writer, sheet_name='ç´¯è¨ˆçµ¦ä¸ãƒã‚§ãƒƒã‚¯2', index=False)
        
        processed_data = output.getvalue()
        st.success("âœ… Excelãƒ•ã‚¡ã‚¤ãƒ«ã®å‡ºåŠ›æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    
    return processed_data, summary

# ------------------------------------------------------------------------------------
# Streamlit UIéƒ¨åˆ†
# ------------------------------------------------------------------------------------

st.set_page_config(page_title="é€€è·çµ¦ä»˜å‚µå‹™ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯", layout="wide")

st.title('é€€è·çµ¦ä»˜å‚µå‹™ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯ã‚¢ãƒ—ãƒª ğŸ“Š')

st.write("""
ã“ã®ã‚¢ãƒ—ãƒªã¯ã€å‰æœŸæœ«ãƒ»å½“æœŸæœ«ãƒ»é€€è·è€…ã®Excelãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã§ã€
ãƒ‡ãƒ¼ã‚¿ã®ä¸æ•´åˆã‚„ã‚¨ãƒ©ãƒ¼ã‚’è‡ªå‹•ã§ãƒã‚§ãƒƒã‚¯ã—ã€çµæœã‚’Excelãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å‡ºåŠ›ã—ã¾ã™ã€‚
""")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.header("âš™ï¸ ãƒ‡ãƒ¼ã‚¿æŒ‡å®šè¨­å®š")
    
    st.subheader("1. ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š")
    sheet_zenki = st.text_input("â‘  å‰æœŸæœ«ãƒ‡ãƒ¼ã‚¿ã®ã‚·ãƒ¼ãƒˆå", "å¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ")
    sheet_touki = st.text_input("â‘¡ å½“æœŸæœ«ãƒ‡ãƒ¼ã‚¿ã®ã‚·ãƒ¼ãƒˆå", "å¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ")
    sheet_taishoku = st.text_input("â‘¢ é€€è·è€…ãƒ‡ãƒ¼ã‚¿ã®ã‚·ãƒ¼ãƒˆå", "é€€è·è€…ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ")
    
    st.subheader("2. åˆ—åè¨­å®š")
    col_employee_id = st.text_input("å¾“æ¥­å“¡ç•ªå·ã®åˆ—å", "å¾“æ¥­å“¡ç•ªå·")
    col_nyusha = st.text_input("å…¥ç¤¾å¹´æœˆæ—¥ã®åˆ—å", "å…¥ç¤¾å¹´æœˆæ—¥")
    col_seinengappi = st.text_input("ç”Ÿå¹´æœˆæ—¥ã®åˆ—å", "ç”Ÿå¹´æœˆæ—¥")
    col_salary1 = st.text_input("çµ¦ä¸1ã®åˆ—å", "çµ¦ä¸ï¼‘") # ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã«åˆã‚ã›ã‚‹
    col_salary2 = st.text_input("çµ¦ä¸2ã®åˆ—å", "çµ¦ä¸ï¼’") # ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã«åˆã‚ã›ã‚‹
    
    st.header("ğŸ” ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯è¨­å®š")
    
    st.subheader("3. è¿½åŠ ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯é …ç›®")
    salary_decrease_check = st.checkbox("çµ¦ä¸æ¸›é¡ãƒã‚§ãƒƒã‚¯", value=True)
    salary_increase_rate_check = st.checkbox("çµ¦ä¸å¢—åŠ ç‡ãƒã‚§ãƒƒã‚¯", value=True)
    x_rate = st.number_input("å¢—åŠ ç‡(x) %", min_value=0.0, value=5.0, step=1.0, format="%.1f")
    cumulative_salary_check = st.checkbox("ç´¯è¨ˆçµ¦ä¸ãƒã‚§ãƒƒã‚¯", value=True)
    y_months = st.number_input("æœˆæ•°(y)", min_value=0, max_value=12, value=1, step=11)
    cumulative_salary_check2 = st.checkbox("ç´¯è¨ˆçµ¦ä¸ãƒã‚§ãƒƒã‚¯2", value=True)
    z_rate = st.number_input("è¶…éç‡(z) %", min_value=0.0, value=0.0, step=1.0, format="%.1f")
    
    error_check_config = {
        "salary_decrease_check": salary_decrease_check,
        "salary_increase_rate_check": salary_increase_rate_check,
        "x_rate": x_rate,
        "cumulative_salary_check": cumulative_salary_check,
        "y_months": y_months,
        "cumulative_salary_check2": cumulative_salary_check2,
        "z_rate": z_rate,
    }

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
st.header("ğŸ“‚ Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
uploaded_zenki = st.file_uploader("â‘  å‰æœŸæœ«å¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿", type=['xlsx', 'xls'])
uploaded_touki = st.file_uploader("â‘¡ å½“æœŸæœ«å¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿", type=['xlsx', 'xls'])
uploaded_taishoku = st.file_uploader("â‘¢ å½“æœŸé€€è·è€…ãƒ‡ãƒ¼ã‚¿", type=['xlsx', 'xls'])


# --- å®Ÿè¡Œãƒœã‚¿ãƒ³ã¨å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ ---
if st.button('ãƒã‚§ãƒƒã‚¯é–‹å§‹', type="primary", use_container_width=True):
    if uploaded_zenki and uploaded_touki and uploaded_taishoku:
        
        df_zenki = find_header_and_read_excel(uploaded_zenki, sheet_zenki, ['å¾“æ¥­å“¡ç•ªå·', 'ç”Ÿå¹´æœˆæ—¥', 'çµ¦ä¸'])
        df_touki = find_header_and_read_excel(uploaded_touki, sheet_touki, ['å¾“æ¥­å“¡ç•ªå·', 'ç”Ÿå¹´æœˆæ—¥', 'çµ¦ä¸'])
        df_taishoku = find_header_and_read_excel(uploaded_taishoku, sheet_taishoku, ['å¾“æ¥­å“¡ç•ªå·', 'ç”Ÿå¹´æœˆæ—¥', 'é€€è·'])
        
        if df_zenki is not None and df_touki is not None and df_taishoku is not None:
            result_excel, summary = data_check_and_matching(
                df_zenki, df_touki, df_taishoku,
                col_employee_id, col_nyusha, col_seinengappi,
                col_salary1, col_salary2,
                error_check_config
            )
            
            st.header("ğŸ‰ å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

            st.subheader("ãƒã‚§ãƒƒã‚¯çµæœã®æ¦‚è¦")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ã‚­ãƒ¼é‡è¤‡(å‰æœŸ)", f"{summary.get('zenki_duplicates', 0)} ä»¶")
                st.metric("ã‚­ãƒ¼é‡è¤‡(å½“æœŸ)", f"{summary.get('touki_duplicates', 0)} ä»¶")
                st.metric("åœ¨ç±è€…æ•°", f"{summary.get('both', 0)} äºº")
            with col2:
                st.metric("æ—¥ä»˜ã‚¨ãƒ©ãƒ¼(å‰æœŸ)", f"{summary.get('zenki_age_errors', 0)} ä»¶")
                st.metric("æ—¥ä»˜ã‚¨ãƒ©ãƒ¼(å½“æœŸ)", f"{summary.get('touki_age_errors', 0)} ä»¶")
                st.metric("å…¥ç¤¾è€…æ•°", f"{summary.get('only_touki', 0)} äºº")
            with col3:
                st.metric("é€€è·è€…ç…§åˆ(ãƒ‡ãƒ¼ã‚¿ä¸åœ¨)", f"{summary.get('retiree_missing', 0)} ä»¶")
                st.metric("é€€è·è€…ç…§åˆ(å€™è£œã§ãªã„)", f"{summary.get('retiree_not_candidate', 0)} ä»¶")
                st.metric("é€€è·è€…æ•°", f"{summary.get('only_zenki', 0)} äºº")
            with col4:
                st.metric("çµ¦ä¸æ¸›é¡", f"{summary.get('salary_decrease', 0)} ä»¶", delta_color="inverse")
                st.metric("çµ¦ä¸å¢—åŠ ç‡(x%)", f"{summary.get('salary_increase_rate', 0)} ä»¶", delta_color="inverse")
                st.metric("ç´¯è¨ˆçµ¦ä¸", f"{summary.get('cumulative_salary_check', 0)} ä»¶", delta_color="inverse")
                st.metric("ç´¯è¨ˆçµ¦ä¸2", f"{summary.get('cumulative_salary_check2', 0)} ä»¶", delta_color="inverse")

            st.download_button(
                label="ğŸ“¥ çµæœã‚’Excelãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=result_excel,
                file_name="check_result.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
    else:
        st.warning("âš ï¸ 3ã¤ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")