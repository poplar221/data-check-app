import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import io

# ------------------------------------------------------------------------------------
# STEP 1: ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢æ•° (ã“ã®éƒ¨åˆ†ã¯å¤‰æ›´ã‚ã‚Šã¾ã›ã‚“)
# ------------------------------------------------------------------------------------

def find_header_and_read_excel(file_path, sheet_name, keywords):
    """
    Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€æŒ‡å®šã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹è¡Œã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã—ã¦ç‰¹å®šã—ã€
    ãã®è¡Œã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§DataFrameã¨ã—ã¦è¿”ã—ã¾ã™ã€‚
    """
    try:
        df_temp = pd.read_excel(file_path, sheet_name=sheet_name, header=None)
        header_row_index = -1
        for i, row in df_temp.iterrows():
            row_str = ''.join(map(str, row.values))
            if all(keyword in row_str for keyword in keywords):
                header_row_index = i
                break
        
        if header_row_index != -1:
            st.info(f"ğŸ“„ '{file_path.name}' ã® '{sheet_name}' ã‚·ãƒ¼ãƒˆã‹ã‚‰ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ {header_row_index + 1} è¡Œç›®ã§ç™ºè¦‹ã—ã¾ã—ãŸã€‚")
            df = pd.read_excel(file_path, sheet_name=sheet_name, header=header_row_index)
            return df
        else:
            st.error(f"âš ï¸ '{file_path.name}' ã® '{sheet_name}' ã‚·ãƒ¼ãƒˆã§ãƒ˜ãƒƒãƒ€ãƒ¼è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return None
    except Exception as e:
        st.error(f"âŒã‚¨ãƒ©ãƒ¼: '{file_path.name}' ã® '{sheet_name}' ã‚·ãƒ¼ãƒˆèª­ã¿è¾¼ã¿ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

def data_check_and_matching(df_zenki, df_touki, df_taishoku, col_nyusha, col_seinengappi, col_employee_id):
    """
    ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯ã¨ãƒãƒƒãƒãƒ³ã‚°å‡¦ç†ã‚’è¡Œã„ã€çµæœã‚’Excelãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ¡ãƒ¢ãƒªä¸Šã«ä¿å­˜ã—ã¾ã™ã€‚
    """
    st.write("---")
    st.subheader("å‡¦ç†çŠ¶æ³")
    
    with st.spinner("STEP 1: å‰å‡¦ç†ã¨ã‚­ãƒ¼ä½œæˆã‚’å®Ÿè¡Œä¸­..."):
        dfz = df_zenki.copy()
        dft = df_touki.copy()
        dftai = df_taishoku.copy()
        
        for df in [dfz, dft, dftai]:
            if col_nyusha in df.columns and col_seinengappi in df.columns:
                df[col_nyusha] = pd.to_datetime(df[col_nyusha].astype(str), errors='coerce')
                df[col_seinengappi] = pd.to_datetime(df[col_seinengappi].astype(str), errors='coerce')

        if col_employee_id in dfz.columns and col_employee_id in dft.columns:
            st.info(f"ğŸ”‘ ã€Œ{col_employee_id}ã€ã‚’ã‚­ãƒ¼ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚")
            for df in [dfz, dft, dftai]:
                df['key'] = df[col_employee_id].astype(str)
        else:
            st.info(f"ğŸ”‘ ã€Œå…¥ç¤¾å¹´æœˆæ—¥ã€ã¨ã€Œç”Ÿå¹´æœˆæ—¥ã€ã®é€£çµæ–‡å­—åˆ—ã‚’ã‚­ãƒ¼ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚")
            for df in [dfz, dft, dftai]:
                df['key'] = df[col_nyusha].dt.strftime('%Y%m%d') + '_' + df[col_seinengappi].dt.strftime('%Y%m%d')
        st.success("âœ… ã‚­ãƒ¼ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    with st.spinner("STEP 2: ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œä¸­..."):
        zenki_duplicates = dfz[dfz.duplicated(subset=['key'], keep=False)]
        touki_duplicates = dft[dft.duplicated(subset=['key'], keep=False)]
        
        zenki_age_errors = pd.DataFrame()
        touki_age_errors = pd.DataFrame()
        if col_nyusha in dfz.columns and col_seinengappi in dfz.columns:
            days_diff_z = (dfz[col_nyusha] - dfz[col_seinengappi]).dt.days
            dfz['age_at_hire'] = (days_diff_z / 365.25).astype(int)
            zenki_age_errors = dfz[(dfz['age_at_hire'] < 15) | (dfz['age_at_hire'] >= 90)]

        if col_nyusha in dft.columns and col_seinengappi in dft.columns:
            days_diff_t = (dft[col_nyusha] - dft[col_seinengappi]).dt.days
            dft['age_at_hire'] = (days_diff_t / 365.25).astype(int)
            touki_age_errors = dft[(dft['age_at_hire'] < 15) | (dft['age_at_hire'] >= 90)]
        st.success("âœ… ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    
    with st.spinner("STEP 3 & 4: ãƒãƒƒãƒãƒ³ã‚°ã¨é€€è·è€…ç…§åˆã‚’å®Ÿè¡Œä¸­..."):
        merged_df = pd.merge(dfz[['key']], dft[['key']], on='key', how='outer', indicator=True)
        only_zenki_keys = merged_df[merged_df['_merge'] == 'left_only']
        only_touki_keys = merged_df[merged_df['_merge'] == 'right_only']
        only_zenki_full = pd.merge(only_zenki_keys, dfz, on='key', how='left')
        only_touki_full = pd.merge(only_touki_keys, dft, on='key', how='left')

        retiree_merged = pd.merge(only_zenki_keys[['key']], dftai[['key']], on='key', how='outer', indicator='retiree_check')
        retiree_missing_keys = retiree_merged[retiree_merged['retiree_check'] == 'left_only']
        retiree_not_candidate_keys = retiree_merged[retiree_merged['retiree_check'] == 'right_only']
        retiree_correct_keys = retiree_merged[retiree_merged['retiree_check'] == 'both']

        retiree_missing_full = pd.merge(retiree_missing_keys, dfz, on='key', how='left')
        retiree_not_candidate_full = pd.merge(retiree_not_candidate_keys, dftai, on='key', how='left')
        retiree_correct_full = pd.merge(retiree_correct_keys, dftai, on='key', how='left')
        st.success("âœ… ãƒãƒƒãƒãƒ³ã‚°ã¨é€€è·è€…ç…§åˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    with st.spinner("STEP 5: çµæœã‚’Excelãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ä¸­..."):
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            zenki_duplicates.to_excel(writer, sheet_name='å‰æœŸæœ«_ã‚­ãƒ¼é‡è¤‡', index=False)
            touki_duplicates.to_excel(writer, sheet_name='å½“æœŸæœ«_ã‚­ãƒ¼é‡è¤‡', index=False)
            zenki_age_errors.to_excel(writer, sheet_name='å‰æœŸæœ«_æ—¥ä»˜ã‚¨ãƒ©ãƒ¼', index=False)
            touki_age_errors.to_excel(writer, sheet_name='å½“æœŸæœ«_æ—¥ä»˜ã‚¨ãƒ©ãƒ¼', index=False)
            only_zenki_full.to_excel(writer, sheet_name='åœ¨ç±ç…§åˆ_å‰æœŸã®ã¿', index=False)
            only_touki_full.to_excel(writer, sheet_name='åœ¨ç±ç…§åˆ_å½“æœŸã®ã¿', index=False)
            retiree_missing_full.to_excel(writer, sheet_name='é€€è·è€…ç…§åˆ_ãƒ‡ãƒ¼ã‚¿ä¸åœ¨', index=False)
            retiree_not_candidate_full.to_excel(writer, sheet_name='é€€è·è€…ç…§åˆ_å€™è£œã§ãªã„', index=False)
            retiree_correct_full.to_excel(writer, sheet_name='é€€è·è€…ç…§åˆ_ä¸€è‡´', index=False)
        
        processed_data = output.getvalue()
        st.success("âœ… Excelãƒ•ã‚¡ã‚¤ãƒ«ã®å‡ºåŠ›æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    
    return processed_data

# ------------------------------------------------------------------------------------
# STEP 2: Streamlitã®UIéƒ¨åˆ†
# ------------------------------------------------------------------------------------

st.set_page_config(page_title="é€€è·çµ¦ä»˜å‚µå‹™ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯", layout="wide")

st.title('é€€è·çµ¦ä»˜å‚µå‹™ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯ã‚¢ãƒ—ãƒª')

st.write("""
ã“ã®ã‚¢ãƒ—ãƒªã¯ã€å‰æœŸæœ«ãƒ»å½“æœŸæœ«ãƒ»é€€è·è€…ã®Excelãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã§ã€\n
ãƒ‡ãƒ¼ã‚¿ã®ä¸æ•´åˆã‚„ã‚¨ãƒ©ãƒ¼ã‚’è‡ªå‹•ã§ãƒã‚§ãƒƒã‚¯ã—ã€çµæœã‚’Excelãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å‡ºåŠ›ã—ã¾ã™ã€‚
""")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¨­å®šé …ç›®ã‚’ä½œæˆ ---
with st.sidebar:
    st.header("1. ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š")
    # â˜…â˜…â˜… ä¿®æ­£ç®‡æ‰€â‘ : ã‚·ãƒ¼ãƒˆåå…¥åŠ›ã‚’3ã¤ã«åˆ†å‰² â˜…â˜…â˜…
    sheet_zenki = st.text_input("â‘  å‰æœŸæœ«ãƒ‡ãƒ¼ã‚¿ã®ã‚·ãƒ¼ãƒˆå", "data")
    sheet_touki = st.text_input("â‘¡ å½“æœŸæœ«ãƒ‡ãƒ¼ã‚¿ã®ã‚·ãƒ¼ãƒˆå", "data")
    sheet_taishoku = st.text_input("â‘¢ é€€è·è€…ãƒ‡ãƒ¼ã‚¿ã®ã‚·ãƒ¼ãƒˆå", "data")
    
    st.header("2. åˆ—åè¨­å®š")
    col_employee_id = st.text_input("å¾“æ¥­å“¡ç•ªå·ã®åˆ—å", "å¾“æ¥­å“¡ç•ªå·")
    col_nyusha = st.text_input("å…¥ç¤¾å¹´æœˆæ—¥ã®åˆ—å", "å…¥ç¤¾å¹´æœˆæ—¥")
    col_seinengappi = st.text_input("ç”Ÿå¹´æœˆæ—¥ã®åˆ—å", "ç”Ÿå¹´æœˆæ—¥")

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’è¨­ç½® ---
st.header("3. Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
uploaded_zenki = st.file_uploader("â‘  å‰æœŸæœ«å¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿", type=['xlsx'])
uploaded_touki = st.file_uploader("â‘¡ å½“æœŸæœ«å¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿", type=['xlsx'])
uploaded_taishoku = st.file_uploader("â‘¢ å½“æœŸé€€è·è€…ãƒ‡ãƒ¼ã‚¿", type=['xlsx'])


# --- ãƒã‚§ãƒƒã‚¯é–‹å§‹ãƒœã‚¿ãƒ³ã¨å‡¦ç† ---
if st.button('ãƒã‚§ãƒƒã‚¯é–‹å§‹', type="primary"):
    if uploaded_zenki and uploaded_touki and uploaded_taishoku:
        
        # â˜…â˜…â˜… ä¿®æ­£ç®‡æ‰€â‘¡: ãã‚Œãã‚Œã®ã‚·ãƒ¼ãƒˆåã‚’ä½¿ã£ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ â˜…â˜…â˜…
        df_zenki = find_header_and_read_excel(uploaded_zenki, sheet_zenki, ['å…¥ç¤¾', 'ç”Ÿå¹´', 'çµ¦ä¸'])
        df_touki = find_header_and_read_excel(uploaded_touki, sheet_touki, ['å…¥ç¤¾', 'ç”Ÿå¹´', 'çµ¦ä¸'])
        df_taishoku = find_header_and_read_excel(uploaded_taishoku, sheet_taishoku, ['å…¥ç¤¾', 'ç”Ÿå¹´'])
        
        if df_zenki is not None and df_touki is not None and df_taishoku is not None:
            result_excel = data_check_and_matching(
                df_zenki, df_touki, df_taishoku,
                col_nyusha, col_seinengappi, col_employee_id
            )
            
            st.header("ğŸ‰ å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            
            st.download_button(
                label="ğŸ“¥ çµæœã‚’Excelãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=result_excel,
                file_name="check_result.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
    else:
        st.warning("âš ï¸ 3ã¤ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")