# app.py

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import io

# ------------------------------------------------------------------------------------
# ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢æ•°
# ------------------------------------------------------------------------------------

def find_header_and_read_excel(file_path, sheet_name, keywords):
    """
    Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€æŒ‡å®šã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹è¡Œã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã—ã¦ç‰¹å®šã—ã€
    ãã®è¡Œã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§DataFrameã¨ã—ã¦è¿”ã—ã¾ã™ã€‚
    """
    if file_path is None:
        return None
    try:
        df_temp = pd.read_excel(file_path, sheet_name=sheet_name, header=None)
        header_row_index = -1
        for i, row in df_temp.iterrows():
            row_str = ''.join(map(str, row.dropna().values))
            if all(keyword in row_str for keyword in keywords):
                header_row_index = i
                break
        
        if header_row_index != -1:
            st.info(f"ğŸ“„ '{file_path.name}' ã® '{sheet_name}' ã‚·ãƒ¼ãƒˆã‹ã‚‰ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ {header_row_index + 1} è¡Œç›®ã§ç™ºè¦‹ã—ã¾ã—ãŸã€‚")
            df = pd.read_excel(file_path, sheet_name=sheet_name, header=header_row_index)
            return df
        else:
            st.error(f"âš ï¸ '{file_path.name}' ã® '{sheet_name}' ã‚·ãƒ¼ãƒˆã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€ãƒ˜ãƒƒãƒ€ãƒ¼è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return None
    except Exception as e:
        st.error(f"âŒã‚¨ãƒ©ãƒ¼: '{file_path.name}' ã® '{sheet_name}' ã‚·ãƒ¼ãƒˆèª­ã¿è¾¼ã¿ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

def data_check_and_matching(df_zenki, df_touki, df_taishoku, col_nyusha, col_seinengappi, col_employee_id):
    """
    ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯ã¨ãƒãƒƒãƒãƒ³ã‚°å‡¦ç†ã‚’è¡Œã„ã€çµæœã‚’Excelãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ¡ãƒ¢ãƒªä¸Šã«ä¿å­˜ã—ã€
    ã‚µãƒãƒªãƒ¼æƒ…å ±ã‚‚ä¸€ç·’ã«è¿”ã—ã¾ã™ã€‚
    """
    # â˜…â˜…â˜… ä¿®æ­£ç®‡æ‰€â‘ : ã‚µãƒãƒªãƒ¼æƒ…å ±ã‚’æ ¼ç´ã™ã‚‹è¾æ›¸ã‚’åˆæœŸåŒ– â˜…â˜…â˜…
    summary = {}
    
    st.write("---")
    st.subheader("å‡¦ç†çŠ¶æ³")
    
    with st.spinner("STEP 1: å‰å‡¦ç†ã¨ã‚­ãƒ¼ä½œæˆã‚’å®Ÿè¡Œä¸­..."):
        dfz = df_zenki.copy()
        dft = df_touki.copy()
        dftai = df_taishoku.copy()
        all_dfs = [dfz, dft, dftai]
        
        for df in all_dfs:
            if col_nyusha in df.columns and col_seinengappi in df.columns:
                df[col_nyusha] = pd.to_datetime(df[col_nyusha].astype(str), errors='coerce')
                df[col_seinengappi] = pd.to_datetime(df[col_seinengappi].astype(str), errors='coerce')

        if col_employee_id in dfz.columns and col_employee_id in dft.columns and col_employee_id in dftai.columns:
            st.info(f"ğŸ”‘ ã€Œ{col_employee_id}ã€ã‚’ã‚­ãƒ¼ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚")
            for df in all_dfs:
                df['key'] = df[col_employee_id].astype(str)
        else:
            st.info(f"ğŸ”‘ ã€Œå…¥ç¤¾å¹´æœˆæ—¥ã€ã¨ã€Œç”Ÿå¹´æœˆæ—¥ã€ã®é€£çµæ–‡å­—åˆ—ã‚’ã‚­ãƒ¼ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚")
            for df in all_dfs:
                if col_nyusha in df.columns and col_seinengappi in df.columns:
                    df['key'] = df[col_nyusha].dt.strftime('%Y%m%d') + '_' + df[col_seinengappi].dt.strftime('%Y%m%d')
        st.success("âœ… ã‚­ãƒ¼ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    with st.spinner("STEP 2: ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œä¸­..."):
        zenki_duplicates = dfz[dfz.duplicated(subset=['key'], keep=False)]
        touki_duplicates = dft[dft.duplicated(subset=['key'], keep=False)]
        summary['zenki_duplicates'] = len(zenki_duplicates)
        summary['touki_duplicates'] = len(touki_duplicates)
        
        zenki_age_errors = pd.DataFrame()
        touki_age_errors = pd.DataFrame()
        if col_nyusha in dfz.columns and col_seinengappi in dfz.columns:
            days_diff_z = (dfz[col_nyusha] - dfz[col_seinengappi]).dt.days
            dfz['age_at_hire'] = (days_diff_z / 365.25).astype(int)
            zenki_age_errors = dfz[(dfz['age_at_hire'] < 15) | (dfz['age_at_hire'] >= 90)]

        if col_nyusha in dft.columns and col_seinengappi in dft.columns:
            days_diff_t = (dft[col_nyusha] - dft[col_seinengappi]).dt.days
            dft['age_at_hire'] = (days_diff_t / 365.25).astype(int)
            touki_age_errors = dft[(dft['age_at_hire'] < 15) | (dft['age_at_hire'] >= 90)]
        summary['zenki_age_errors'] = len(zenki_age_errors)
        summary['touki_age_errors'] = len(touki_age_errors)
        st.success("âœ… ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    
    with st.spinner("STEP 3 & 4: ãƒãƒƒãƒãƒ³ã‚°ã¨é€€è·è€…ç…§åˆã‚’å®Ÿè¡Œä¸­..."):
        merged_df = pd.merge(dfz[['key']], dft[['key']], on='key', how='outer', indicator=True)
        only_zenki_keys = merged_df[merged_df['_merge'] == 'left_only']
        only_touki_keys = merged_df[merged_df['_merge'] == 'right_only']
        only_zenki_full = pd.merge(only_zenki_keys, dfz, on='key', how='left')
        only_touki_full = pd.merge(only_touki_keys, dft, on='key', how='left')
        summary['only_zenki'] = len(only_zenki_full)
        summary['only_touki'] = len(only_touki_full)

        retiree_merged = pd.merge(only_zenki_keys[['key']], dftai[['key']], on='key', how='outer', indicator='retiree_check')
        retiree_missing_keys = retiree_merged[retiree_merged['retiree_check'] == 'left_only']
        retiree_not_candidate_keys = retiree_merged[retiree_merged['retiree_check'] == 'right_only']
        retiree_correct_keys = retiree_merged[retiree_merged['retiree_check'] == 'both']

        retiree_missing_full = pd.merge(retiree_missing_keys, dfz, on='key', how='left')
        retiree_not_candidate_full = pd.merge(retiree_not_candidate_keys, dftai, on='key', how='left')
        retiree_correct_full = pd.merge(retiree_correct_keys, dftai, on='key', how='left')
        summary['retiree_missing'] = len(retiree_missing_full)
        summary['retiree_not_candidate'] = len(retiree_not_candidate_full)
        summary['retiree_correct'] = len(retiree_correct_full)
        st.success("âœ… ãƒãƒƒãƒãƒ³ã‚°ã¨é€€è·è€…ç…§åˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    with st.spinner("STEP 5: çµæœã‚’Excelãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ä¸­..."):
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            zenki_duplicates.to_excel(writer, sheet_name='å‰æœŸæœ«_ã‚­ãƒ¼é‡è¤‡', index=False)
            touki_duplicates.to_excel(writer, sheet_name='å½“æœŸæœ«_ã‚­ãƒ¼é‡è¤‡', index=False)
            zenki_age_errors.to_excel(writer, sheet_name='å‰æœŸæœ«_æ—¥ä»˜ã‚¨ãƒ©ãƒ¼', index=False)
            touki_age_errors.to_excel(writer, sheet_name='å½“æœŸæœ«_æ—¥ä»˜ã‚¨ãƒ©ãƒ¼', index=False)
            only_zenki_full.to_excel(writer, sheet_name='åœ¨ç±ç…§åˆ_å‰æœŸã®ã¿', index=False)
            only_touki_full.to_excel(writer, sheet_name='åœ¨ç±ç…§åˆ_å½“æœŸã®ã¿', index=False)
            retiree_missing_full.to_excel(writer, sheet_name='é€€è·è€…ç…§åˆ_ãƒ‡ãƒ¼ã‚¿ä¸åœ¨', index=False)
            retiree_not_candidate_full.to_excel(writer, sheet_name='é€€è·è€…ç…§åˆ_å€™è£œã§ãªã„', index=False)
            retiree_correct_full.to_excel(writer, sheet_name='é€€è·è€…ç…§åˆ_ä¸€è‡´', index=False)
        
        processed_data = output.getvalue()
        st.success("âœ… Excelãƒ•ã‚¡ã‚¤ãƒ«ã®å‡ºåŠ›æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    
    # â˜…â˜…â˜… ä¿®æ­£ç®‡æ‰€â‘¡: Excelãƒ‡ãƒ¼ã‚¿ã¨ã‚µãƒãƒªãƒ¼æƒ…å ±ã®ä¸¡æ–¹ã‚’è¿”ã™ â˜…â˜…â˜…
    return processed_data, summary

# ------------------------------------------------------------------------------------
# Streamlit UIéƒ¨åˆ†
# ------------------------------------------------------------------------------------

st.set_page_config(page_title="é€€è·çµ¦ä»˜å‚µå‹™ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯", layout="wide")
st.title('é€€è·çµ¦ä»˜å‚µå‹™ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯ã‚¢ãƒ—ãƒª ğŸ“Š')
st.write("""
ã“ã®ã‚¢ãƒ—ãƒªã¯ã€å‰æœŸæœ«ãƒ»å½“æœŸæœ«ãƒ»é€€è·è€…ã®Excelãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã§ã€
ãƒ‡ãƒ¼ã‚¿ã®ä¸æ•´åˆã‚„ã‚¨ãƒ©ãƒ¼ã‚’è‡ªå‹•ã§ãƒã‚§ãƒƒã‚¯ã—ã€çµæœã‚’Excelãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å‡ºåŠ›ã—ã¾ã™ã€‚
""")

with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    st.subheader("1. ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š")
    sheet_zenki = st.text_input("â‘  å‰æœŸæœ«ãƒ‡ãƒ¼ã‚¿ã®ã‚·ãƒ¼ãƒˆå", "å¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ")
    sheet_touki = st.text_input("â‘¡ å½“æœŸæœ«ãƒ‡ãƒ¼ã‚¿ã®ã‚·ãƒ¼ãƒˆå", "å¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ")
    sheet_taishoku = st.text_input("â‘¢ é€€è·è€…ãƒ‡ãƒ¼ã‚¿ã®ã‚·ãƒ¼ãƒˆå", "é€€è·è€…ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ")
    
    st.subheader("2. åˆ—åè¨­å®š")
    col_employee_id = st.text_input("å¾“æ¥­å“¡ç•ªå·ã®åˆ—å", "å¾“æ¥­å“¡ç•ªå·")
    col_nyusha = st.text_input("å…¥ç¤¾å¹´æœˆæ—¥ã®åˆ—å", "å…¥ç¤¾å¹´æœˆæ—¥")
    col_seinengappi = st.text_input("ç”Ÿå¹´æœˆæ—¥ã®åˆ—å", "ç”Ÿå¹´æœˆæ—¥")

st.header("ğŸ“‚ Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
uploaded_zenki = st.file_uploader("â‘  å‰æœŸæœ«å¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿", type=['xlsx', 'xls'])
uploaded_touki = st.file_uploader("â‘¡ å½“æœŸæœ«å¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿", type=['xlsx', 'xls'])
uploaded_taishoku = st.file_uploader("â‘¢ å½“æœŸé€€è·è€…ãƒ‡ãƒ¼ã‚¿", type=['xlsx', 'xls'])

if st.button('ãƒã‚§ãƒƒã‚¯é–‹å§‹', type="primary", use_container_width=True):
    if uploaded_zenki and uploaded_touki and uploaded_taishoku:
        df_zenki = find_header_and_read_excel(uploaded_zenki, sheet_zenki, ['å…¥ç¤¾', 'ç”Ÿå¹´', 'çµ¦ä¸'])
        df_touki = find_header_and_read_excel(uploaded_touki, sheet_touki, ['å…¥ç¤¾', 'ç”Ÿå¹´', 'çµ¦ä¸'])
        df_taishoku = find_header_and_read_excel(uploaded_taishoku, sheet_taishoku, ['å…¥ç¤¾', 'ç”Ÿå¹´'])
        
        if df_zenki is not None and df_touki is not None and df_taishoku is not None:
            # â˜…â˜…â˜… ä¿®æ­£ç®‡æ‰€â‘¢: ã‚µãƒãƒªãƒ¼æƒ…å ±ã‚‚å—ã‘å–ã‚‹ â˜…â˜…â˜…
            result_excel, summary = data_check_and_matching(
                df_zenki, df_touki, df_taishoku,
                col_nyusha, col_seinengappi, col_employee_id
            )
            
            st.header("ğŸ‰ å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

            # â˜…â˜…â˜… ä¿®æ­£ç®‡æ‰€â‘£: ã‚µãƒãƒªãƒ¼ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’è¡¨ç¤º â˜…â˜…â˜…
            st.subheader("ãƒã‚§ãƒƒã‚¯çµæœã®æ¦‚è¦")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ã‚­ãƒ¼é‡è¤‡(å‰æœŸ)", f"{summary.get('zenki_duplicates', 0)} ä»¶")
                st.metric("ã‚­ãƒ¼é‡è¤‡(å½“æœŸ)", f"{summary.get('touki_duplicates', 0)} ä»¶")
            with col2:
                st.metric("æ—¥ä»˜ã‚¨ãƒ©ãƒ¼(å‰æœŸ)", f"{summary.get('zenki_age_errors', 0)} ä»¶")
                st.metric("æ—¥ä»˜ã‚¨ãƒ©ãƒ¼(å½“æœŸ)", f"{summary.get('touki_age_errors', 0)} ä»¶")
            with col3:
                st.metric("é€€è·è€…ç…§åˆ(ãƒ‡ãƒ¼ã‚¿ä¸åœ¨)", f"{summary.get('retiree_missing', 0)} ä»¶")
                st.metric("é€€è·è€…ç…§åˆ(å€™è£œã§ãªã„)", f"{summary.get('retiree_not_candidate', 0)} ä»¶")

            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            st.download_button(
                label="ğŸ“¥ çµæœã‚’Excelãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=result_excel,
                file_name="check_result.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
    else:
        st.warning("âš ï¸ 3ã¤ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")